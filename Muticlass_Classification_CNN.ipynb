{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6XcUm4oo1ID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transfroms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "SEED = 111\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"GPU Available: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "FOU_nnN9pRSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/archive\n",
        "!ls"
      ],
      "metadata": {
        "id": "jD4k3FwDpX0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom Dataset class for training\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# DataFrame for training data\n",
        "def generate_df(data_path):\n",
        "    classes, class_paths = zip(*[(label, os.path.join(label, image))\n",
        "                                for label in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, label))\n",
        "                                for image in os.listdir(os.path.join(data_path, label))])\n",
        "\n",
        "    df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n",
        "    return df\n",
        "\n",
        "# training and testing data\n",
        "TEST_DIR = '/content/gdrive/My Drive/archive/Testing'\n",
        "TRAIN_DIR = '/content/gdrive/My Drive/archive/Training'\n",
        "\n",
        "# Generate DataFrames\n",
        "tr_df = generate_df(TRAIN_DIR)\n",
        "ts_df = generate_df(TEST_DIR)\n",
        "\n",
        "# Label encoding to assign numerical classes\n",
        "label_mapping = {label: idx for idx, label in enumerate(tr_df['Class'].unique())}\n",
        "tr_df['Class'] = tr_df['Class'].map(label_mapping)\n",
        "ts_df['Class'] = ts_df['Class'].map(label_mapping)\n",
        "\n",
        "# Data transformations\n",
        "transform = T.Compose([\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomResizedCrop(32),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Initialize the custom dataset\n",
        "train_dataset = CustomImageDataset(tr_df, root_dir=TRAIN_DIR, transform=transform)\n",
        "test_dataset = CustomImageDataset(ts_df, root_dir=TEST_DIR, transform=transform)\n",
        "\n",
        "# Load data using DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "nP2D4ayQpacv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot the count of images per class\n",
        "ax = sns.countplot(data=tr_df, y='Class', order=tr_df['Class'].value_counts().index)\n",
        "\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.title('Count of Images in Training Data', fontsize=20)\n",
        "\n",
        "# Add count labels to each bar\n",
        "ax.bar_label(ax.containers[0])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7gJMqju6sR64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot the count of images per class\n",
        "ax = sns.countplot(data=ts_df, y='Class', order=ts_df['Class'].value_counts().index)\n",
        "\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.title('Count of Images in Testing Data', fontsize=20)\n",
        "\n",
        "# Add count labels to each bar\n",
        "ax.bar_label(ax.containers[0])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CqYkVk4XtAOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Parameters\n",
        "image_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Define data augmentation and normalization for training data\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15),  # Approximating brightness_range\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(degrees=12.5, shear=12.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define normalization only for testing data\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Get class indices and their corresponding names\n",
        "class_indices_train = train_dataset.class_to_idx\n",
        "class_indices_train_list = list(train_dataset.classes)\n",
        "\n",
        "# Display the class indices for training data\n",
        "print(\"Categorical types for the training data:\")\n",
        "print(class_indices_train)\n",
        "\n",
        "# Image shape: height, width, RGB\n",
        "image_shape = (image_size[0], image_size[1], 3)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 40\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(test_loader)\n",
        "\n",
        "print(f'Image shape: {image_shape}')\n",
        "print(f'Epochs: {epochs}')\n",
        "print(f'Batch size: {batch_size}')\n",
        "print(f'Steps Per Epoch: {steps_per_epoch}')\n",
        "print(f'Validation Steps: {validation_steps}')\n"
      ],
      "metadata": {
        "id": "AKz06wjOtQ3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "N_TYPES = len(class_indices_train)\n",
        "\n",
        "#cited from: https://www.kaggle.com/code/guslovesmath/cnn-brain-tumor-classification-99-accuracy the structure of CNN models\n",
        "# Define the model architecture\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=1, padding=0)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=0)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=1, padding=0)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=4, stride=1, padding=0)\n",
        "\n",
        "        # Calculate the size after flattening the last convolutional layer\n",
        "        self.flatten_size = 128 * 2 * 2\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(nn.ReLU()(self.conv1(x)))\n",
        "        x = self.pool2(nn.ReLU()(self.conv2(x)))\n",
        "        x = self.pool3(nn.ReLU()(self.conv3(x)))\n",
        "        x = nn.ReLU()(self.conv4(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return nn.Softmax(dim=1)(x)\n",
        "\n",
        "# Instantiate the model and print its summary\n",
        "model = ConvNet(num_classes=N_TYPES).to(device)\n",
        "print(model)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.869, 0.995))\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "GZ9lCHI4ugai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "# Define a dummy input tensor\n",
        "dummy_input = torch.randn(1, 3, *image_size).to(device)\n",
        "\n",
        "# produce a computation graph\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Visualize the graph using torchviz\n",
        "make_dot(output, params=dict(model.named_parameters())).render(\"model_architecture\", format=\"png\")\n"
      ],
      "metadata": {
        "id": "Qg1hMexMu1m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to collect training and validation statistics\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# training loop to collect statistics\n",
        "num_epochs = 40\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    running_train_correct = 0\n",
        "    total_train_samples = 0\n",
        "\n",
        "    # Training phase\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_train_correct += torch.sum(preds == labels)\n",
        "        total_train_samples += labels.size(0)\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    train_accuracy = running_train_correct.double() / total_train_samples\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "    train_acc_history.append(train_accuracy.item())\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    running_val_correct = 0\n",
        "    total_val_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_val_correct += torch.sum(preds == labels)\n",
        "            total_val_samples += labels.size(0)\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(test_loader)\n",
        "    val_accuracy = running_val_correct.double() / total_val_samples\n",
        "    val_loss_history.append(avg_val_loss)\n",
        "    val_acc_history.append(val_accuracy.item())\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
        "          f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# Plot training and validation statistics\n",
        "_, ax = plt.subplots(ncols=2, figsize=(15, 6))\n",
        "\n",
        "# Accuracy plot\n",
        "ax[0].plot(train_acc_history)\n",
        "ax[0].plot(val_acc_history)\n",
        "ax[0].set_title('Model Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].legend(['Train', 'Validation'])\n",
        "ax[0].grid(alpha=0.2)\n",
        "\n",
        "# Loss plot\n",
        "ax[1].plot(train_loss_history)\n",
        "ax[1].plot(val_loss_history)\n",
        "ax[1].set_title('Model Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].legend(['Train', 'Validation'])\n",
        "ax[1].grid(alpha=0.2)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ti0NQ2A7vZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Collect all true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "\n",
        "# Label formatting\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks(ticks=np.arange(N_TYPES) + 0.5, labels=[name.title() for name in class_indices_train_list], ha='center')\n",
        "plt.yticks(ticks=np.arange(N_TYPES) + 0.5, labels=[name.title() for name in class_indices_train_list], va='center')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8hTfBejnv8nT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}